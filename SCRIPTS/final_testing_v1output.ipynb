{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Testing phase\n",
    "\n",
    "### Goal: Using Keras, implement _______________\n",
    "\n",
    "\n",
    "### Install the following libraries:\n",
    "\n",
    "pip install numpy\n",
    "\n",
    "pip install pandas\n",
    "\n",
    "pip install scikit-learn\n",
    "\n",
    "pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/eyf3gu/.local/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (68.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sfs/weka/scratch/eyf3gu/DS4002/DS4002Project3/SCRIPTS\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 12:20:25.333984: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 12:20:25.366415: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 12:20:26.927352: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-20 12:20:27.180236: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732123227.663816  523770 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732123227.809897  523770 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 12:20:28.838534: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 25 classes.\n",
      "Found 2000 images belonging to 25 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eyf3gu/.local/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-11-20 12:20:45.368950: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eyf3gu/.local/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 127ms/step - accuracy: 0.0561 - loss: 3.1907 - val_accuracy: 0.1545 - val_loss: 2.8708\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.1875 - loss: 2.7512 - val_accuracy: 0.3180 - val_loss: 2.3316\n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.3560 - loss: 2.1317 - val_accuracy: 0.5060 - val_loss: 1.7718\n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.5705 - loss: 1.4189 - val_accuracy: 0.6550 - val_loss: 1.3720\n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.7578 - loss: 0.7953 - val_accuracy: 0.7595 - val_loss: 1.1985\n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.8984 - loss: 0.3402 - val_accuracy: 0.7825 - val_loss: 1.3186\n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9452 - loss: 0.1791 - val_accuracy: 0.7735 - val_loss: 1.7257\n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9643 - loss: 0.1270 - val_accuracy: 0.7980 - val_loss: 1.8767\n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9634 - loss: 0.1288 - val_accuracy: 0.8020 - val_loss: 1.6435\n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9722 - loss: 0.0989 - val_accuracy: 0.8040 - val_loss: 1.7622\n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.9816 - loss: 0.0633 - val_accuracy: 0.8030 - val_loss: 1.9135\n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9724 - loss: 0.0912 - val_accuracy: 0.8025 - val_loss: 2.0072\n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.9875 - loss: 0.0395 - val_accuracy: 0.8035 - val_loss: 2.1906\n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9789 - loss: 0.0662 - val_accuracy: 0.8120 - val_loss: 2.0782\n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 128ms/step - accuracy: 0.9873 - loss: 0.0396 - val_accuracy: 0.7965 - val_loss: 2.0712\n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.9744 - loss: 0.0820 - val_accuracy: 0.8020 - val_loss: 2.0370\n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9900 - loss: 0.0331 - val_accuracy: 0.8050 - val_loss: 2.1635\n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - accuracy: 0.9838 - loss: 0.0535 - val_accuracy: 0.7685 - val_loss: 2.4957\n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.9712 - loss: 0.0897 - val_accuracy: 0.7980 - val_loss: 2.3087\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9823 - loss: 0.0570 - val_accuracy: 0.8085 - val_loss: 2.2048\n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9884 - loss: 0.0325 - val_accuracy: 0.8080 - val_loss: 2.3218\n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - accuracy: 0.9944 - loss: 0.0207 - val_accuracy: 0.7795 - val_loss: 3.1851\n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - accuracy: 0.9609 - loss: 0.1286 - val_accuracy: 0.8090 - val_loss: 2.3013\n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9869 - loss: 0.0478 - val_accuracy: 0.8030 - val_loss: 2.4589\n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9897 - loss: 0.0320 - val_accuracy: 0.8140 - val_loss: 2.4573\n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - accuracy: 0.9868 - loss: 0.0471 - val_accuracy: 0.8095 - val_loss: 2.3150\n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 127ms/step - accuracy: 0.9874 - loss: 0.0449 - val_accuracy: 0.8100 - val_loss: 2.6379\n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 0.9849 - loss: 0.0559 - val_accuracy: 0.8030 - val_loss: 2.4829\n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 129ms/step - accuracy: 0.9866 - loss: 0.0444 - val_accuracy: 0.8055 - val_loss: 2.6399\n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 129ms/step - accuracy: 0.9857 - loss: 0.0554 - val_accuracy: 0.8045 - val_loss: 2.5629\n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9927 - loss: 0.0187 - val_accuracy: 0.8095 - val_loss: 2.5793\n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9885 - loss: 0.0456 - val_accuracy: 0.8110 - val_loss: 2.3352\n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9917 - loss: 0.0302 - val_accuracy: 0.7935 - val_loss: 2.6543\n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9875 - loss: 0.0387 - val_accuracy: 0.7875 - val_loss: 2.6469\n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9794 - loss: 0.0727 - val_accuracy: 0.8160 - val_loss: 2.5530\n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9934 - loss: 0.0245 - val_accuracy: 0.8060 - val_loss: 2.9002\n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9875 - loss: 0.0425 - val_accuracy: 0.8050 - val_loss: 2.5442\n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9803 - loss: 0.0635 - val_accuracy: 0.8110 - val_loss: 2.5002\n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 0.9939 - loss: 0.0244 - val_accuracy: 0.8205 - val_loss: 2.5906\n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9894 - loss: 0.0353 - val_accuracy: 0.8075 - val_loss: 2.4021\n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9880 - loss: 0.0422 - val_accuracy: 0.8170 - val_loss: 2.6117\n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9951 - loss: 0.0154 - val_accuracy: 0.8185 - val_loss: 2.7117\n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9947 - loss: 0.0157 - val_accuracy: 0.8115 - val_loss: 2.9723\n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9941 - loss: 0.0197 - val_accuracy: 0.8195 - val_loss: 2.7680\n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 126ms/step - accuracy: 0.9978 - loss: 0.0061 - val_accuracy: 0.8195 - val_loss: 3.0304\n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9852 - loss: 0.0592 - val_accuracy: 0.7925 - val_loss: 2.4308\n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9817 - loss: 0.0674 - val_accuracy: 0.8145 - val_loss: 2.3930\n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 0.9943 - loss: 0.0177 - val_accuracy: 0.8155 - val_loss: 2.5955\n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 0.9998 - loss: 0.0022 - val_accuracy: 0.8190 - val_loss: 2.5627\n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 2.3746e-04 - val_accuracy: 0.8200 - val_loss: 2.6060\n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.2955e-04 - val_accuracy: 0.8225 - val_loss: 2.6415\n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 6.2844e-05 - val_accuracy: 0.8230 - val_loss: 2.6668\n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 125ms/step - accuracy: 1.0000 - loss: 4.6677e-05 - val_accuracy: 0.8215 - val_loss: 2.6899\n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 4.0309e-05 - val_accuracy: 0.8215 - val_loss: 2.7121\n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.4112e-05 - val_accuracy: 0.8215 - val_loss: 2.7340\n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 3.0113e-05 - val_accuracy: 0.8215 - val_loss: 2.7553\n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 2.5506e-05 - val_accuracy: 0.8220 - val_loss: 2.7765\n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 2.1470e-05 - val_accuracy: 0.8210 - val_loss: 2.7975\n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.7721e-05 - val_accuracy: 0.8210 - val_loss: 2.8188\n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 1.3666e-05 - val_accuracy: 0.8210 - val_loss: 2.8393\n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.2965e-05 - val_accuracy: 0.8210 - val_loss: 2.8604\n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 1.1248e-05 - val_accuracy: 0.8210 - val_loss: 2.8814\n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 1.0434e-05 - val_accuracy: 0.8210 - val_loss: 2.9021\n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 8.5954e-06 - val_accuracy: 0.8210 - val_loss: 2.9235\n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.3724e-06 - val_accuracy: 0.8210 - val_loss: 2.9445\n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 6.2454e-06 - val_accuracy: 0.8210 - val_loss: 2.9662\n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 5.6953e-06 - val_accuracy: 0.8215 - val_loss: 2.9876\n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 5.1311e-06 - val_accuracy: 0.8220 - val_loss: 3.0092\n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 4.2266e-06 - val_accuracy: 0.8220 - val_loss: 3.0306\n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.7277e-06 - val_accuracy: 0.8220 - val_loss: 3.0524\n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.2669e-06 - val_accuracy: 0.8220 - val_loss: 3.0739\n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 2.7108e-06 - val_accuracy: 0.8220 - val_loss: 3.0937\n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.3498e-06 - val_accuracy: 0.8225 - val_loss: 3.1163\n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.9846e-06 - val_accuracy: 0.8225 - val_loss: 3.1383\n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.8254e-06 - val_accuracy: 0.8215 - val_loss: 3.1624\n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.4998e-06 - val_accuracy: 0.8215 - val_loss: 3.1874\n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.3110e-06 - val_accuracy: 0.8220 - val_loss: 3.2071\n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.1290e-06 - val_accuracy: 0.8215 - val_loss: 3.2318\n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 9.3564e-07 - val_accuracy: 0.8215 - val_loss: 3.2543\n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 8.5910e-07 - val_accuracy: 0.8215 - val_loss: 3.2783\n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 7.2231e-07 - val_accuracy: 0.8215 - val_loss: 3.2993\n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 6.2844e-07 - val_accuracy: 0.8220 - val_loss: 3.3236\n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 5.5120e-07 - val_accuracy: 0.8225 - val_loss: 3.3449\n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 4.8266e-07 - val_accuracy: 0.8220 - val_loss: 3.3697\n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 4.1889e-07 - val_accuracy: 0.8215 - val_loss: 3.3907\n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.6881e-07 - val_accuracy: 0.8220 - val_loss: 3.4163\n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 3.1697e-07 - val_accuracy: 0.8220 - val_loss: 3.4375\n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 2.5687e-07 - val_accuracy: 0.8220 - val_loss: 3.4609\n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 2.4603e-07 - val_accuracy: 0.8220 - val_loss: 3.4846\n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 2.0473e-07 - val_accuracy: 0.8220 - val_loss: 3.5076\n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.8303e-07 - val_accuracy: 0.8220 - val_loss: 3.5321\n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.5878e-07 - val_accuracy: 0.8220 - val_loss: 3.5551\n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.3501e-07 - val_accuracy: 0.8220 - val_loss: 3.5786\n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.1801e-07 - val_accuracy: 0.8220 - val_loss: 3.6009\n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 1.0199e-07 - val_accuracy: 0.8220 - val_loss: 3.6240\n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 9.2113e-08 - val_accuracy: 0.8220 - val_loss: 3.6465\n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 7.7838e-08 - val_accuracy: 0.8220 - val_loss: 3.6695\n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 6.9772e-08 - val_accuracy: 0.8220 - val_loss: 3.6912\n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 5.8302e-08 - val_accuracy: 0.8220 - val_loss: 3.7147\n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 5.0451e-08 - val_accuracy: 0.8220 - val_loss: 3.7359\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8358 - loss: 3.3360\n",
      "Validation Accuracy: 0.8220000267028809\n",
      "Accuracy data saved to celebs_accuracy.csv.\n"
     ]
    }
   ],
   "source": [
    "# install libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split # for splitting data into training / test sets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "data_dir = \"/sfs/weka/scratch/eyf3gu/DS4002/DS4002Project3/DATA/celebrities_all\" # set base directory\n",
    "image_size = (150, 150)  # Resize images to 150 x 150\n",
    "batch_size = 32 # batch size refers to the number of images that will be processed at a time before the model's parameters are reset. \n",
    "# we chose this number becuase it is relatively standard.\n",
    "epochs = 100 # we settled on 100 epochs for the testing phase\n",
    "\n",
    "# using ImageDataGenerator, load / preprocess the images\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "# the \"rescale\" parameter scales down the range of pixel sizes in the images to between 0 and 1. This helps with processing speed.\n",
    "# \"validation-split\" defines a 20/80 test/training split (0.2 = ratio of images placed in testing category)\n",
    "\n",
    "# Training data generator -- method to produce a set of images based on chosen characteristics\n",
    "train_generator = datagen.flow_from_directory( \n",
    "    data_dir, # specifies path to target directory (\"celebrities_all\")\n",
    "    target_size=image_size, # standardizes image size to 150 x 150, as specified earlier\n",
    "    batch_size=batch_size, # batch size is 32, as specified earlier\n",
    "    class_mode='categorical', # the model will be identifying celeb images, where each celeb is a different \"class\". Celeb is a categorical variable\n",
    "    subset='training' # the generator will pull the training images, which make up 80% of the celebrities_all images.\n",
    ")\n",
    "\n",
    "# Validation data generator -- repeating the steps used to define the train_generator. Parameters are the same, but the generator will pull from the 20% of images in the test (validation) set\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation' # pulling from the validation set\n",
    ")\n",
    "\n",
    "# Now, we will build a simple CNN model using Keras. \n",
    "# First, using the models.sequential class, a sequential model will be created to produce a stack of layers. Each layer will have an input\n",
    "# sensor and an output sensor. This will create a \"feed-forward\" neural network wherein each layer is directly connected to the one before it.\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3. Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# 4. Evaluate the model and store accuracies\n",
    "accuracy_results = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {accuracy_results[1]}\")\n",
    "\n",
    "# Create a DataFrame to store the accuracy of each image\n",
    "celebs_accuracy = pd.DataFrame({\n",
    "    \"image_path\": validation_generator.filenames,\n",
    "    \"accuracy\": [accuracy_results[1]] * len(validation_generator.filenames)\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "celebs_accuracy.to_csv(\"celebs_accuracy.csv\", index=False)\n",
    "\n",
    "print(\"Accuracy data saved to celebs_accuracy.csv.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
