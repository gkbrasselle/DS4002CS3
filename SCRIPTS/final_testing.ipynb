{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Testing phase\n",
    "\n",
    "### Goal: Using Keras, train a CNN model to correctly identify celebrity images. Utilize 100 training epochs. See Keras documentation in the ReadMe file citations.\n",
    "\n",
    "\n",
    "### Install the following libraries:\n",
    "\n",
    "pip install numpy\n",
    "\n",
    "pip install pandas\n",
    "\n",
    "pip install scikit-learn\n",
    "\n",
    "pip install tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/eyf3gu/.local/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (68.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/eyf3gu/.local/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/eyf3gu/.local/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /apps/software/standard/core/jupyterlab/3.6.3-py3.11/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/eyf3gu/.local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# install libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split # for splitting data into training / test sets\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # \n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "data_dir = \" \" # set base directory\n",
    "image_size = (150, 150)  # Resize images to 150 x 150\n",
    "batch_size = 32 # batch size refers to the number of images that will be processed at a time before the model's parameters are reset. \n",
    "# we chose this number becuase it is relatively standard.\n",
    "epochs = 100 # we settled on 100 epochs for the testing phase\n",
    "\n",
    "# using ImageDataGenerator, load / preprocess the images\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "# the \"rescale\" parameter scales down the range of pixel sizes in the images to between 0 and 1. This helps with processing speed.\n",
    "# \"validation-split\" defines a 20/80 test/training split (0.2 = ratio of images placed in testing category)\n",
    "\n",
    "# Training data generator -- method to produce a set of images based on chosen characteristics\n",
    "train_generator = datagen.flow_from_directory( \n",
    "    data_dir, # specifies path to target directory (\"celebrities_all\")\n",
    "    target_size=image_size, # standardizes image size to 150 x 150, as specified earlier\n",
    "    batch_size=batch_size, # batch size is 32, as specified earlier\n",
    "    class_mode='categorical', # the model will be identifying celeb images, where each celeb is a different \"class\". Celeb is a categorical variable\n",
    "    subset='training' # the generator will pull the training images, which make up 80% of the celebrities_all images.\n",
    ")\n",
    "\n",
    "# Validation data generator -- repeating the steps used to define the train_generator. Parameters are the same, but the generator will pull from the 20% of images in the test (validation) set\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation', # pulling from the validation set\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Now, we will build a simple CNN model using Keras. \n",
    "# First, using the models.sequential class, a sequential model will be created to produce a stack of layers. Each layer will have an input\n",
    "# sensor and an output sensor. This will create a \"feed-forward\" neural network wherein each layer is directly connected to the one before it.\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    # First convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),  # Dropout for regularization\n",
    "\n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Fourth convolutional block\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),  # Increased filter depth\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Flattening and fully connected layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),  # Higher dropout for dense layers\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = {\n",
    "    \"epoch\": [],\n",
    "    \"filename\": [],\n",
    "    \"true_class\": [],\n",
    "    \"predicted_class\": [],\n",
    "    \"confidence\": []\n",
    "}\n",
    "\n",
    "\n",
    "class LoggingCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, validation_generator):\n",
    "        self.validation_generator = validation_generator\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        predictions = self.model.predict(self.validation_generator)\n",
    "        predicted_classes = predictions.argmax(axis=1)\n",
    "        true_classes = self.validation_generator.classes\n",
    "        filenames = self.validation_generator.filenames\n",
    "\n",
    "        for i, file in enumerate(filenames):\n",
    "            results[\"epoch\"].append(epoch + 1)\n",
    "            results[\"filename\"].append(file)\n",
    "            results[\"true_class\"].append(true_classes[i])\n",
    "            results[\"predicted_class\"].append(predicted_classes[i])\n",
    "            results[\"confidence\"].append(predictions[i, predicted_classes[i]])\n",
    "\n",
    "# Add callback and train the model\n",
    "logger_callback = LoggingCallback(validation_generator)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[logger_callback]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_results = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {accuracy_results[1]}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"epoch_results.csv\", index=False)\n",
    "print(\"Results saved to epoch_results.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
